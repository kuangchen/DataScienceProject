{
 "metadata": {
  "name": "",
  "signature": "sha256:354435f45f90b00efa91af9a405c1575fafcf7aad1cec26ab9fdf86e7f5f8eb2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Book recommendation system using item-based collaborative filtering\n",
      "\n",
      "Kuang Chen\n",
      "\n",
      "July 2014"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recommendation systems are uniquitous for every area of our daily life that. (just think about Google, LinkedIn, RottenTomato, Amazon, LastFM, TripAdvisor, TrueCar and other countless companies out there.) Based on the stored historical user action (purchasing/browsing/rating...), these systems predict what an user would also like, beyond what he/she has already shown preference of. There is a variety of different statistical models from which a recommendation system can be built. One such popular model is called \"item-based collaborative filtering\", that _directly_ calculates the similarity between items. \n",
      "\n",
      "Here is how this algorithm works: mathematically, user $u$ indicate his preference, represented by rating $R_{u,j}$, of $j$-th item. Then the recommendation algorithm predicts $P_{u,i}$, the rating he would give to i-$^{th}$ item that has not been rated yet \n",
      "\n",
      "<center>\n",
      "$P_{u, i} = \\dfrac{ \\sum_{j} s_{kj} R_{u, j}}{\\sum_{j}|s_{kj}|}$\n",
      "</center>\n",
      "\n",
      "where the weight factor $s_{kj}$ is a measure of **similarity**: the larger $r_{kj}$ is, the more similar $u_k$ and $u_j$ are. \n",
      "There are various metrics based on which the similarity matrix $s_{kj}$ could be constructed. (Refer to Ref [X] for an overview). In this tutorial I am going to use the adjusted cosine similarity: we collect the historial ratings $R_{u, k}$ that another user $u$ give to the $k$-th item , \n",
      "\n",
      "<center>\n",
      "$s_{kj} = \\dfrac{\\sum_{u} (R_{u, k}-\\overline{R}_u)(R_{u, j}-\\overline{R}_u)}{\\sqrt{\\sum_{u}(R_{u, k}-\\overline{R}_u)^2}\\sqrt{\\sum_{u}(R_{u, j}-\\overline{R}_u)^2}}$\n",
      "</center>\n",
      "\n",
      "where $\\overline{R}_u$, the average of the $u$-th user's ratings is subtracted to adjust for each person's rating bias. \n",
      "\n",
      "In this tutorial, I am going to build a book recommendation system based on this principle. We use the data from the _Book-Crossing Dataset_ (see Ref []). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 30)\n",
      "\n",
      "#these colors come from colorbrewer2.org. Each is an RGB triplet\n",
      "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
      "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
      "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
      "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
      "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
      "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
      "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),\n",
      "                (0.4, 0.4, 0.4)]\n",
      "\n",
      "rcParams['figure.figsize'] = (10, 6)\n",
      "rcParams['figure.dpi'] = 150\n",
      "rcParams['axes.color_cycle'] = dark2_colors\n",
      "rcParams['lines.linewidth'] = 2\n",
      "rcParams['axes.grid'] = False\n",
      "rcParams['axes.facecolor'] = 'white'\n",
      "rcParams['font.size'] = 14\n",
      "rcParams['patch.edgecolor'] = 'none'\n",
      "\n",
      "\n",
      "def remove_border(axes=None, top=False, right=False, left=True, bottom=True):\n",
      "    \"\"\"\n",
      "    Minimize chartjunk by stripping out unnecessary plot borders and axis ticks\n",
      "    \n",
      "    The top/right/left/bottom keywords toggle whether the corresponding plot border is drawn\n",
      "    \"\"\"\n",
      "    ax = axes or plt.gca()\n",
      "    ax.spines['top'].set_visible(top)\n",
      "    ax.spines['right'].set_visible(right)\n",
      "    ax.spines['left'].set_visible(left)\n",
      "    ax.spines['bottom'].set_visible(bottom)\n",
      "    \n",
      "    #turn off all ticks\n",
      "    ax.yaxis.set_ticks_position('none')\n",
      "    ax.xaxis.set_ticks_position('none')\n",
      "    \n",
      "    #now re-enable visibles\n",
      "    if top:\n",
      "        ax.xaxis.tick_top()\n",
      "    if bottom:\n",
      "        ax.xaxis.tick_bottom()\n",
      "    if left:\n",
      "        ax.yaxis.tick_left()\n",
      "    if right:\n",
      "        ax.yaxis.tick_right()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We define the core Recommender class here. The key part is the metric function, which builds the similarity matrix. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import scipy.sparse as sparse\n",
      "import scipy.spatial.distance as distance\n",
      "import numpy.linalg as linalg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def nonzero_element(r, row=True):\n",
      "    '''\n",
      "    return the non-zero element of a sparse.csc_matrix\n",
      "    r: the sparse matrix\n",
      "    row: if set to True, non-zero elements of r is split into rows\n",
      "         otherwise split for each column\n",
      "    '''\n",
      "    if row:\n",
      "        return [ r.data[r.indices==i] for i in range(r.shape[0]) ]\n",
      "    \n",
      "    else:\n",
      "        return split(r.data, r.indptr)[1:-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_bias(r):\n",
      "    mu = r.data.mean()\n",
      "    \n",
      "    bu = zeros(r.shape[0])\n",
      "    for i in range(r.shape[0]):\n",
      "        bu[i] = r.data[r.indices==i].mean() - mu\n",
      "    \n",
      "    bi = zeros(r.shape[1])    \n",
      "    for i, col in enumerate(split(r.data, r.indptr)[1:-1]):\n",
      "        bi[i] = col.mean() - bu[r.indices[r.indptr[i]:r.indptr[i+1]]].mean() - mu\n",
      "    \n",
      "    return mu, bu, bi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext cythonmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "cimport cython\n",
      "cimport numpy as np\n",
      "import scipy.sparse as sparse\n",
      "import numpy as np\n",
      "import scipy.spatial.distance\n",
      "@cython.wraparound(False)\n",
      "@cython.cdivision(True)\n",
      "def adjusted_cosine(rating):\n",
      "    cdef:\n",
      "        int i, j\n",
      "        double b\n",
      "        # Use memoryview object to store row mean, and similarity matrix\n",
      "        double [:] m = np.zeros(rating.shape[0])\n",
      "        double [:, :] s = np.identity(rating.shape[1])\n",
      "        #np.ndarray(double, ndim=1) rid, rjd\n",
      "        \n",
      "    # Use the following trick to realize r -= r.mena(axis=1)\n",
      "    # http://stackoverflow.com/questions/16043299/substitute-for-numpy-broadcasting-using-scipy-sparse-csc-matrix\n",
      "    r = rating.tocsc()\n",
      "    for i in range(r.shape[0]):\n",
      "        row_i = r.data[r.indices==i]\n",
      "        if (row_i.size!=0):\n",
      "            m[i] = row_i.mean()\n",
      "        \n",
      "    # Convert r to float for subtraction\n",
      "    r = r.asfptype()\n",
      "    r.data -= np.take(m, r.indices)\n",
      "    \n",
      "    r_indices = [ rating.indices[rating.indptr[i]:rating.indptr[i+1]] for i in range(s.shape[0]) ]\n",
      "        \n",
      "    for i, j in zip(*scipy.triu_indices_from(s, k=1)):\n",
      "        ri_indices, rj_indices = r_indices[i], r_indices[j]     \n",
      "        #ri, rj = r.getcol(i), r.getcol(j)\n",
      "        # Get the indices of all users who only rated\n",
      "        # ith or jth item, but not both\n",
      "        # and ignore these ratings\n",
      "        rid = r.data[np.where(np.in1d(ri_indices, rj_indices)) + r.indptr[i]]\n",
      "        rjd = r.data[np.where(np.in1d(rj_indices, ri_indices)) + r.indptr[j]]     \n",
      "        \n",
      "        b = 0\n",
      "        \n",
      "        if rid.size!=0:\n",
      "            b = 1 - scipy.spatial.distance.cosine(rid, rjd)\n",
      "            if np.isnan(b):\n",
      "                b = 0\n",
      "                \n",
      "        s[i, j], s[j, i] = b, b\n",
      "    \n",
      "    return sparse.csr_matrix(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 232
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The BookRecommender System"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class BookRecommender:\n",
      "    def __init__(self, book_df, rating_df, metric):\n",
      "        self._book_df = book_df\n",
      "        self._rating_df = rating_df\n",
      "        \n",
      "        rating_matrix = sparse.csc_matrix(self._rating_df.fillna(0).values)\n",
      "        self._recommender = Recommender(rating_matrix, metric)\n",
      "        \n",
      "    def _item_idx_to_book(self, item_idx):        \n",
      "        return self._rating_df.columns[item_idx]\n",
      "    \n",
      "    def _book_to_item_idx(self, book_title):                \n",
      "        return [ self._rating_df.columns.get_loc(bt) for bt in book_title ]\n",
      "        \n",
      "    def display_cover(self, book_title):        \n",
      "        return self._book_df.ix[self._book_df[\"Book-Title\"].isin(book_title), \"Image-URL-M\"]\n",
      "            \n",
      "    def recommend(self, pref, top=10):\n",
      "        idx = self._book_to_item_idx(pref[0])\n",
      "        score = pref[1]\n",
      "        \n",
      "        predicted_idx = self._recommender.recommend((idx, score))\n",
      "        predicted_book = self._item_idx_to_book(predicted_idx)\n",
      "        return predicted_book\n",
      "    #    return self._item_to_book(predicted_item_id)        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 287
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Loading the data\n",
      "The book and rating datasets are both loaded with <code>read_csv</code> functions. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_rating_df = pd.read_csv(\"BX-Book-Ratings.csv\", encoding = \"ISO-8859-1\", sep=\";\")\n",
      "col_names = [\"ISBN\", \"Book-Title\", \"Book-Author\", \"Year-Of-Publication\", \"Publisher\", \"Image-URL-S\", \"Image-URL-M\", \"Image-URL-L\"]\n",
      "all_book_df = pd.read_csv(\"BX-Books.csv\",encoding = \"ISO-8859-1\", skiprows=1, names=col_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then we see how many ratings are there per book? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = subplots(2, 1)\n",
      "review_by_book = pd.Series(all_rating_df.ISBN.value_counts(), name=\"review_by_book\")\n",
      "review_by_book.hist(ax=ax[0], bottom=1, bins=arange(1, 1000, 10), edgecolor='white')\n",
      "ax[0].set(xlabel=\"Review per book\", yscale='log')\n",
      "\n",
      "review_by_user = pd.Series(all_rating_df[\"User-ID\"].value_counts(), name=\"review_by_user\")\n",
      "review_by_user.hist(ax=ax[1], bottom=1, bins=arange(1, 1000, 10), edgecolor='white')\n",
      "ax[1].set(xlabel=\"Review per user\", yscale='log')\n",
      "fig.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAsEAAAGjCAYAAADNZci4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f3bd7a42e48>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To have an efficient and reliable recommendation algorithm, we limit our selection of books to those with more than 50 reviews, and our selection of users with more than 100 books. (50 and 100 are roughly where the knees of the above figures are.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "book_review_threshold = 150\n",
      "user_review_threshold = 100\n",
      "\n",
      "rating_df = all_rating_df.join(review_by_book, on='ISBN').join(review_by_user, on='User-ID')\n",
      "rating_df = rating_df[ (rating_df[\"review_by_book\"] > book_review_threshold) & (rating_df[\"review_by_user\"] > user_review_threshold) ]\n",
      "print(rating_df.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(42479, 5)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We then combine the book dataframe with rating dataframe to create a big dataframe, so we can translate the ISBN number to book title. We call <code>pivot_table</code> method of the big dataframe to construct the rating matrix, where each row is a user and each column is an item. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "big_df = pd.merge(all_book_df, rating_df, how='inner')\n",
      "rating_matrix = big_df.pivot_table(index=['User-ID'], columns=['Book-Title'], values='Book-Rating')\n",
      "rating_matrix.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>Book-Title</th>\n",
        "      <th>1984</th>\n",
        "      <th>1st to Die: A Novel</th>\n",
        "      <th>2nd Chance</th>\n",
        "      <th>4 Blondes</th>\n",
        "      <th>A Bend in the Road</th>\n",
        "      <th>A Case of Need</th>\n",
        "      <th>A Child Called It: One Child's Courage to Survive</th>\n",
        "      <th>A Fine Balance</th>\n",
        "      <th>A Heartbreaking Work of Staggering Genius</th>\n",
        "      <th>A Is for Alibi (Kinsey Millhone Mysteries (Paperback))</th>\n",
        "      <th>A Lesson Before Dying (Vintage Contemporaries (Paperback))</th>\n",
        "      <th>A Map of the World</th>\n",
        "      <th>A Painted House</th>\n",
        "      <th>A Prayer for Owen Meany</th>\n",
        "      <th>A Thousand Acres (Ballantine Reader's Circle)</th>\n",
        "      <th>...</th>\n",
        "      <th>We Were the Mulvaneys</th>\n",
        "      <th>Welcome to the World, Baby Girl!</th>\n",
        "      <th>What Looks Like Crazy On An Ordinary Day</th>\n",
        "      <th>When the Wind Blows</th>\n",
        "      <th>Where the Heart Is (Oprah's Book Club (Paperback))</th>\n",
        "      <th>While I Was Gone</th>\n",
        "      <th>White Oleander : A Novel</th>\n",
        "      <th>White Oleander : A Novel (Oprah's Book Club)</th>\n",
        "      <th>White Teeth: A Novel</th>\n",
        "      <th>Who Moved My Cheese? An Amazing Way to Deal with Change in Your Work and in Your Life</th>\n",
        "      <th>Wicked: The Life and Times of the Wicked Witch of the West</th>\n",
        "      <th>Wild Animus</th>\n",
        "      <th>Without Remorse</th>\n",
        "      <th>Year of Wonders</th>\n",
        "      <th>Zen and the Art of Motorcycle Maintenance: An Inquiry into Values</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>User-ID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>254 </th>\n",
        "      <td>  9</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>507 </th>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>882 </th>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1424</th>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  7</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  7</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1435</th>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  7</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  8</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  5</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 342 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "Book-Title  1984  1st to Die: A Novel  2nd Chance  4 Blondes  A Bend in the Road  A Case of Need  A Child Called It: One Child's Courage to Survive  A Fine Balance  A Heartbreaking Work of Staggering Genius  A Is for Alibi (Kinsey Millhone Mysteries (Paperback))  A Lesson Before Dying (Vintage Contemporaries (Paperback))  A Map of the World  A Painted House  A Prayer for Owen Meany  A Thousand Acres (Ballantine Reader's Circle)                      ...                        \\\n",
        "User-ID                                                                                                                                                                                                                                                                                                                                                                                                                                                              ...                         \n",
        "254            9                  NaN         NaN        NaN                 NaN             NaN                                                NaN             NaN                                        NaN                                                NaN                                                     NaN                          NaN              NaN                      NaN                                            NaN                      ...                         \n",
        "507          NaN                  NaN         NaN        NaN                 NaN             NaN                                                NaN             NaN                                        NaN                                                NaN                                                     NaN                          NaN              NaN                      NaN                                            NaN                      ...                         \n",
        "882          NaN                  NaN         NaN        NaN                   0             NaN                                                NaN             NaN                                        NaN                                                NaN                                                     NaN                          NaN              NaN                      NaN                                            NaN                      ...                         \n",
        "1424         NaN                  NaN         NaN        NaN                 NaN             NaN                                                NaN             NaN                                        NaN                                                NaN                                                     NaN                            7              NaN                      NaN                                            NaN                      ...                         \n",
        "1435         NaN                  NaN         NaN        NaN                 NaN               7                                                NaN             NaN                                        NaN                                                NaN                                                     NaN                          NaN                0                      NaN                                            NaN                      ...                         \n",
        "\n",
        "Book-Title  We Were the Mulvaneys  Welcome to the World, Baby Girl!  What Looks Like Crazy On An Ordinary Day  When the Wind Blows  Where the Heart Is (Oprah's Book Club (Paperback))  While I Was Gone  White Oleander : A Novel  White Oleander : A Novel (Oprah's Book Club)  White Teeth: A Novel  Who Moved My Cheese? An Amazing Way to Deal with Change in Your Work and in Your Life  Wicked: The Life and Times of the Wicked Witch of the West  Wild Animus  Without Remorse  Year of Wonders  \\\n",
        "User-ID                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
        "254                           NaN                               NaN                                       NaN                  NaN                                                NaN                NaN                         0                                           NaN                   NaN                                                NaN                                                                                    NaN                   NaN              NaN              NaN   \n",
        "507                           NaN                               NaN                                       NaN                  NaN                                                NaN                NaN                       NaN                                           NaN                   NaN                                                NaN                                                                                    NaN                   NaN              NaN              NaN   \n",
        "882                           NaN                               NaN                                       NaN                  NaN                                                NaN                NaN                       NaN                                           NaN                   NaN                                                NaN                                                                                    NaN                   NaN              NaN              NaN   \n",
        "1424                          NaN                               NaN                                       NaN                  NaN                                                NaN                NaN                       NaN                                           NaN                   NaN                                                NaN                                                                                    NaN                   NaN              NaN                7   \n",
        "1435                          NaN                               NaN                                       NaN                  NaN                                                  8                NaN                       NaN                                           NaN                   NaN                                                NaN                                                                                    NaN                     5              NaN              NaN   \n",
        "\n",
        "Book-Title  Zen and the Art of Motorcycle Maintenance: An Inquiry into Values  \n",
        "User-ID                                                                        \n",
        "254                                                       NaN                  \n",
        "507                                                       NaN                  \n",
        "882                                                       NaN                  \n",
        "1424                                                      NaN                  \n",
        "1435                                                      NaN                  \n",
        "\n",
        "[5 rows x 342 columns]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Building the recommendation engine\n",
      "\n",
      "As you immediately observed, there are a lot of NaNs in the dataframe. Let's count the ratio of NaN to the total number of elements in the dataframe. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"the ratio is %3.3f\" % (rating_matrix.isnull().sum().sum() / rating_matrix.values.size))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the ratio is 0.929\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The sparsity of rating data strongly suggests that to calculate the similarity matrix it would be extremely inefficient to loop through each element in the matrix sequentially. Instead we can take the advantage of the sparse matrix provided by <code>scipy</code>. The general idea is, <code>scipy.sparse</code> indexing the non-zero elements is fast because it store the locations (row, col) of these non-zero elements. Below I will explain the low-level operations of the algorithm, and after that I will introduce the wrapper."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We define a function <code>extract_bias</code> to subtract the user bias and item bias."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_bias(r):\n",
      "    \"\"\"\n",
      "    extract the user and item bias\n",
      "    r: rating matrix, row is user and col is item\n",
      "    \n",
      "    return value:\n",
      "    mu: overall rating bias\n",
      "    bu: bias for each user\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    mu = r.data.mean()   \n",
      "    \n",
      "    bu = zeros(r.shape[0])\n",
      "    for i in range(r.shape[0]):\n",
      "        bu[i] = r.data[r.indices==i].mean() - mu\n",
      "    \n",
      "    return mu, bu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we define the cosine similarity function (the comment in the code should be self-explanatory):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cosine_sim(r, mu, bu, common_support_threshold=25):\n",
      "    \"\"\" \n",
      "    calculate the similarity matrix between the columns \n",
      "    r: rating matrix, row is user and column is item\n",
      "    mu: overall bias\n",
      "    bu: bias for user\n",
      "    common_support_threshold: threshold for the common support length, below which the similarity is \n",
      "        scaled by this number. \n",
      "    \"\"\"\n",
      "    # make sure r is float type\n",
      "    r = r.asfptype()    \n",
      "    # Remove the overall bias and user bias from the data\n",
      "    r.data -= take(bu+mu, r.indices)\n",
      "    \n",
      "    r_indices = split(r.indices, r.indptr)[1:-1]    \n",
      "    s = np.identity(r.shape[1])\n",
      "    \n",
      "    for i, j in zip(*triu_indices_from(s, k=1)):\n",
      "        ri_indices, rj_indices = r_indices[i], r_indices[j]     \n",
      "        # Extract the ith and jth column, and take the common support (i.e. overlap)\n",
      "        rid = r.data[np.where(np.in1d(ri_indices, rj_indices)) + r.indptr[i]]\n",
      "        rjd = r.data[np.where(np.in1d(rj_indices, ri_indices)) + r.indptr[j]]     \n",
      "        \n",
      "        n_common_support = rid.shape[0]\n",
      "        b = 0\n",
      "        \n",
      "        if rid.size!=0:\n",
      "            # calculate the cosine distance, and convert it to cosine similiarty\n",
      "            b = 1 - distance.cosine(rid, rjd) \n",
      "            if np.isnan(b):\n",
      "                b = 0\n",
      "                \n",
      "            # if the length of common support is smaller than threshold\n",
      "            # scale the similarity down, otherwise do nothing\n",
      "            if n_common_support < common_support_threshold:\n",
      "                b *= (float(n_common_support) / (common_support_threshold))\n",
      "            \n",
      "        # register the similarity in the matrix s\n",
      "        s[i, j], s[j, i] = b, b\n",
      "    \n",
      "    # convert s to csr_matrix and return\n",
      "    return sparse.csr_matrix(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below is the code for the recommender engine. The RecommenderEngine class calculates the similiarity matrix from the rating matrix, and recommend the index of top n items that are similar to the indicated preferences. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RecEngine:\n",
      "    def __init__(self, rm, metric=cosine_sim):\n",
      "        \"\"\"\n",
      "        class constructor\n",
      "        rm: rating matrix, row is user, column is item\n",
      "        metric: metric function, which takes rm as input and return the similarity matrix of the rating\n",
      "        \"\"\"\n",
      "        self._rm = rm\n",
      "        self._n_user, self._n_item = rm.shape  \n",
      "        \n",
      "        # Extract the bias for row (user) and column (item) respectively\n",
      "        self._mu, self._bu = extract_bias(rm)\n",
      "        self._sim = metric(self._rm, self._mu, self._bu)\n",
      "        \n",
      "    def predict(self, r):\n",
      "        \"\"\"\n",
      "        Predict usr's rating of un-rated items based on his rating r\n",
      "        r: length-2 tuple. r[0] are the list of item indices, and r[1] are the corresponding ratings \n",
      "        \n",
      "        Return:\n",
      "        p: predicted rating of each item\n",
      "        \"\"\"\n",
      "        # construct \n",
      "        rr = sparse.csc_matrix((r[1], array([r[0], [0]*len(r[0])])), shape=(self._n_item, 1))        \n",
      "        p = zeros(self._n_item)\n",
      "        \n",
      "        for i in range(self._n_item):\n",
      "            a = self._sim[i].dot(rr)\n",
      "            \n",
      "            # if a is empty, then set a = 0 \n",
      "            if len(a.data)==0:\n",
      "                a = 0.0\n",
      "            # otherwise divide a by the sum of weight \n",
      "            else:\n",
      "                w = self._sim[i, intersect1d(rr[:, 0].indices, self._sim[i].indices)].data\n",
      "                a = float(a.data[0]) / fabs(w).sum()\n",
      "                \n",
      "            p[i] = a\n",
      "        \n",
      "        return p\n",
      "        \n",
      "    def recommend(self, r, top_n=10):\n",
      "        \"\"\" \n",
      "        Recommend top n items based on user's rating\n",
      "        top_n: number of recommended items \n",
      "        \n",
      "        return:\n",
      "        (rec_index, rec_rating) which are indices of recommended items and their corresponding rating \n",
      "        \"\"\"\n",
      "        p = self.predict(r)\n",
      "        \n",
      "        rec_index = []\n",
      "        rec_rating = []        \n",
      "        for i in p.argsort()[-1:-top_n-len(r[0])-1:-1]:\n",
      "            if i not in r[0]:\n",
      "                rec_index.append(i)\n",
      "                rec_rating.append(p[i])\n",
      "            \n",
      "                if len(rec_index)==top_n:\n",
      "                    break\n",
      "                    \n",
      "        return rec_index, rec_rating"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 136
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally we write the wrapper code, which translate the book title to item index and vice versa. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class BookRecommender:\n",
      "    def __init__(self, book_df, rating_df, metric):\n",
      "        self._book_df = book_df\n",
      "        self._rating_df = rating_df\n",
      "        \n",
      "        rm = sparse.csc_matrix((self._rating_df+1e-4).fillna(0).values)\n",
      "        self._engine = RecEngine(rm, metric)\n",
      "        \n",
      "    def _item_idx_to_book(self, item_idx):\n",
      "        \"\"\" Translate index to book title \"\"\"\n",
      "        return self._rating_df.columns[item_idx]\n",
      "    \n",
      "    def _book_to_item_idx(self, book_title): \n",
      "        \"\"\" Translate book title to index \"\"\"\n",
      "        return [ self._rating_df.columns.get_loc(bt) for bt in book_title ]\n",
      "        \n",
      "    def display_cover(self, book_title): \n",
      "        \"\"\" Display the book cover \"\"\"\n",
      "        return self._book_df.set_index(\"Book-Title\").ix[book_title, \"Image-URL-M\"].apply(lambda u: display(Image(url=u)))\n",
      "        #self._book_df[self._book_df[\"Book-Title\"].isin(book_title)][\"Image-URL-M\"].apply(lambda u: print(u))\n",
      "            \n",
      "    def recommend(self, r, top_n=10):\n",
      "        \"\"\" Recommend top_n books based on user's rating r \"\"\"\n",
      "        idx = self._book_to_item_idx(r[0])        \n",
      "        rec_index, rec_rating = self._engine.recommend((idx, r[1]), top_n)\n",
      "        \n",
      "        rec_book_title = self._item_idx_to_book(rec_index)\n",
      "        return rec_book_title, rec_rating"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "br = BookRecommender(all_book_df, rating_matrix, metric=cosine_sim)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rec_book_title, rec_rating = br.recommend(r=([\"The Great Gatsby\", \"1984\", \"Animal Farm\"], [7, 9, 6]), top_n=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image, display\n",
      "br.display_cover(rec_book_title)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0375706771.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0380018179.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0380563908.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0060129565.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0449212602.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0449911535.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0395404258.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0745168086.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0345438329.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0345337662.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0345310594.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0452264464.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0671003755.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0399144463.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0385497466.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0440236673.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0553526847.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0375727965.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0553502417.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "html": [
        "<img src=\"http://images.amazon.com/images/P/0060938455.01.MZZZZZZZ.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f3bde18d390>"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 174,
       "text": [
        "Book-Title\n",
        "Midwives: A Novel                                               None\n",
        "The Thorn Birds                                                 None\n",
        "The Thorn Birds                                                 None\n",
        "The Thorn Birds                                                 None\n",
        "The Handmaid's Tale                                             None\n",
        "The Handmaid's Tale                                             None\n",
        "The Handmaid's Tale                                             None\n",
        "The Handmaid's Tale                                             None\n",
        "Big Stone Gap: A Novel (Ballantine Reader's Circle)             None\n",
        "Interview with the Vampire                                      None\n",
        "Interview with the Vampire                                      None\n",
        "Beloved (Plume Contemporary Fiction)                            None\n",
        "She's Come Undone (Oprah's Book Club (Paperback))               None\n",
        "Who Moved My Cheese? An Amazing Way to Deal with Change in Your Work and in Your Life    None\n",
        "The Brethren                                                    None\n",
        "The Brethren                                                    None\n",
        "The Brethren                                                    None\n",
        "The Brethren                                                    None\n",
        "The Brethren                                                    None\n",
        "Fast Food Nation: The Dark Side of the All-American Meal        None\n",
        "Name: Image-URL-M, dtype: object"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## References\n",
      "\n",
      "1. Programming Collective Intelligence: Building Smart Web 2.0 Applications, Toby Segaran, 2007\n",
      "2. Item-based Collaborative Filtering Recommendation Algorithms. B. Sarwar, G. Karypis, J. Konstan,and J. Riedl. Proceedings of the 10th international conference on World Wide Web, http://dl.acm.org/citation.cfm?id=372071\n",
      "3. Book-Crossing Dataset, Cai-Nicolas Ziegler, DBIS Freiburg http://www2.informatik.uni-freiburg.de/~cziegler/BX/\n",
      "4. http://downloads.hindawi.com/journals/aai/2009/421425.pdf"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}